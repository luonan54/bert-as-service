#!/bin/bash
#
# setup-bert
# Install Bert as a Service on Google Kubernetes Engine (GKE)
#
#
# Prerequisites
#
# 1. Install GCloud, gsutil
# https://cloud.google.com/sdk/install
# https://cloud.google.com/storage/docs/gsutil_install
#
# 2. Install Kubectl
# https://kubernetes.io/docs/tasks/tools/install-kubectl/
#
# 3. Install Docker 
# https://docs.docker.com/install/
#
# 4. Create a new project and enable billing,
#    settting GCP_PROJECT below.
# https://console.cloud.google.com/cloud-resource-manager
#
#
FILE=./docker/Dockerfile
if [ ! -f "$FILE" ]; then
   echo "Run this script from the top level directory of Bert As Service."
   exit 1
fi

echo "Welcome to Bert as a Service on GKE!"
echo " "
echo "This script assumes you've already created a GCP project"
echo "and have pointed gcloud to it.  We'll take it from there."
echo "You'll also need to have installed kubectl and docker."
echo " "
read -p "Ready to proceed (y/n)? " choice
case "$choice" in 
  y|Y ) echo "Installing Bert";;
  n|N ) exit;;
  * ) exit;;
esac

# Name of your GCP project for billing, etc.
export GCP_PROJECT=`gcloud config get-value project`
export GCP_ZONE=us-east1-c
export GCP_CLUSTER=bert-cluster

#
# Point gcloud to our new project
#
echo "Pointing gcloud to $GCP_PROJECT"
gcloud config set project $GCP_PROJECT

#
# Required API access (sync)
#
echo "Enabling APIs"
echo "...Identity"
gcloud services enable iam.googleapis.com
gcloud services enable iamcredentials.googleapis.com
echo "...Compute & Storage"
gcloud services enable compute.googleapis.com
gcloud services enable storage-component.googleapis.com
echo "...Kubernetes"
gcloud services enable container.googleapis.com
gcloud services enable containerregistry.googleapis.com
gcloud services enable containeranalysis.googleapis.com
gcloud services enable deploymentmanager.googleapis.com
echo "...Clusters"
gcloud services enable replicapool.googleapis.com
gcloud services enable replicapoolupdater.googleapis.com
#
# Optional API access (async)
#
echo "...AI Platform"
gcloud services enable bigquery.googleapis.com --async
gcloud services enable language.googleapis.com --async
gcloud services enable tpu.googleapis.com --async
gcloud services enable translate.googleapis.com --async
gcloud services enable videointelligence.googleapis.com --async
gcloud services enable vision.googleapis.com --async
gcloud services enable sheets.googleapis.com --async
gcloud services enable runtimeconfig.googleapis.com --async
gcloud services enable logging.googleapis.com --async
gcloud services enable drive.googleapis.com --async
gcloud services enable file.googleapis.com --async
gcloud services enable kgraph.googleapis.com --async
gcloud services enable kgsearch.googleapis.com --async
gcloud services enable pubsub.googleapis.com --async
gcloud services enable monitoring.googleapis.com --async

#
# Choose your GPU accelerators from the list for your region
#
# gcloud compute accelerator-types list
#
# Then go online and reserve sufficient GPUs of your chosen type in your quota
# https://console.cloud.google.com/iam-admin/quotas
#
export GCP_GPU=nvidia-tesla-k80
export GCP_GPU_COUNT=4
export GCP_GPU_POOL=bert-gpu-pool

# create a cluster to use these GPUs
echo "Creating base cluster"
gcloud container clusters create $GCP_CLUSTER \
       --enable-autoscaling --max-nodes=4 --min-nodes=1 \
       --num-nodes 1 --zone $GCP_ZONE 

# create a pool of nodes for the cluster
echo "Creating a pool of beefy GPU nodes"
gcloud container node-pools create $GCP_GPU_POOL \
--cluster=$GCP_CLUSTER --zone=$GCP_ZONE \
--machine-type n1-highmem-8 --disk-type=pd-ssd  --disk-size=256G \
--accelerator=type=$GCP_GPU,count=$GCP_GPU_COUNT \
--num-nodes=1 \
--enable-autoscaling --max-nodes=2 --min-nodes=0  

# hook up kubectl to our cluster
echo "Enabling kubernetes access"
gcloud container clusters get-credentials $GCP_CLUSTER --region=$GCP_ZONE

# install NVidia drivers
echo "Installing GPU device drivers"
kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml

# Build our container image
echo "Building docker container for Bert"
gcloud auth configure-docker
docker build -t bert-as-service -f ./docker/Dockerfile .
docker tag bert-as-service gcr.io/$GCP_PROJECT/bert-as-service
docker push gcr.io/$GCP_PROJECT/bert-as-service

# Reserve a global IP address for our bert service
echo "Getting an IP address"
gcloud compute addresses create bert-ip --global
export GCP_BERT_IP=`gcloud compute addresses list | grep bert-ip | awk '{print $2}'`

# Update our deployment with proper container info
echo "Customizing GKE"
cp docker/bert-deployment.tpl docker/bert-deployment.yaml
sed -i -e "s/CONTAINER_IMAGE/gcr\.io\/$GCP_PROJECT\/bert-as-service/g" docker/bert-deployment.yaml
sed -i -e "s/GPU_COUNT/$GCP_GPU_COUNT/g" docker/bert-deployment.yaml

# Stand up service
echo "Standing up Bert as a service"
kubectl apply -f docker/bert-deployment.yaml
kubectl apply -f docker/bert-as-service.yaml
kubectl apply -f docker/bert-ingress.yaml

echo "Bert will soon be live at $GCP_BERT_IP which you can test with docker/test-bert"
echo " "
echo "Google will need a few minutes now to setup HTTP access in its"
echo "internal routing tables.  You can track the status on the Google Cloud Console"
echo "at https://console.cloud.google.com and then visiting Google Kubernetes Engine"
echo "to track the cluster's Ingress status."
echo " "
echo "Happy Hacking!"

